{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff0b4e8b9274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# TRICKS!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# FIRST, YOU DON'T NEED THE COLUMN NAMES:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Assignment: Final Project - Phase 2\n",
    "# Filename: final_project_2.py\n",
    "# Description: Final Project\n",
    "# Date: 04/19/2020\n",
    "# Author: Tarini Dash\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NAME YOUR DATAFRAMES.  I KNOW DF IS COMMON BUT IT'S ONLY BECAUSE PEOPLE ARE USING IT GENERICALLY WHEN DISCUSSING\n",
    "# PANDAS.  YOU WILL HAVE MORE THAN ONE DATAFRAME IN PROJECTS.\n",
    "\n",
    "# LET ME SHOW YOU A FEW OTHER WAYS TO DO THIS WITHOUT USING DROP, BUT IN ORDER TO DO SO I NEED TO SHOW YOU SOME OTHER\n",
    "# TRICKS!\n",
    "\n",
    "df = df.drop(columns=['Scn', 'Class'])\n",
    "\n",
    "# FIRST, YOU DON'T NEED THE COLUMN NAMES:\n",
    "\n",
    "cols = [\"Scn\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"Class\"] \n",
    "df = pd.read_csv('breast-cancer-wisconsin.data', na_values = '?', names = col)\n",
    "\n",
    "# THEY WILL BE INFERRED BY READ_CS. IF YOU ALREADY HAVE A HEADER THEN YOU CAN JUST DO THIS (ALSO I DON'T THINK YOU \n",
    "# NEED TO REPLACE NaN's WITH '?', I KNOW THAT VEL DOES):\n",
    "\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "print(data.columns) # [\"Scn\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"Class\"]\n",
    "\n",
    "# SEE?  ALREADY INCLUDED!  AND, YOU CAN ALWAYS SEE THE HEADER USING THE .columns PROPERTY OF THE DATAFRAME. OF \n",
    "# COURSE YOU CAN CHANGE THE COLUMNS EXCLUDE THEM ENTIRELY IN read_csv.  TAKE A LOOK AT read_csv API.   \n",
    "\n",
    "# THE columns PROPERTY IS LIKE A LIST, IT'S NOT, BUT YOU CAN DO THIS WITH IT TO REMOVE COLUMNS SO LONG AS THEY ARE\n",
    "# CONTINUOUS:\n",
    "\n",
    "data = data[data.columns[1:-1]]\n",
    "\n",
    "# OR\n",
    "\n",
    "data = data[data.columns[:4]]\n",
    "\n",
    "# BUT IF YOU MAKE THEM INTO A LIST, YOU CAN ALSO REORDER AND DROP COLUMNS IN THE MIDDLE LIKE SO:\n",
    "\n",
    "cols = list(data.columns)\n",
    "data = data[cols[6:] + cols[:6]]\n",
    "print(data.columns) [ \"A7\", \"A8\", \"A9\", \"A10\", \"Class\", \"Scn\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "\n",
    "# IN ORDER TO AVOID HAVING TO DO THAT FOR EACH FUNCTION, I DID IT ONCE AT THE BEGINNING AS A SEPPERATE DATASET YOU\n",
    "# COULD LOAD IT AS original AND THEN SET A DATAFRAME WITHOUT THE FIRST AND LAST COLUMNS TO DATA OR SOMETHING.  YOU\n",
    "# THEN, I JUST WORKED WITH THAT DATA FRAME, AND ADDED data['Predicted'] to original['Predicted'] AT THE PART I NEEDED\n",
    "# TO, BUT THEN IF I HAD TO DO ANOTHER LOOP, I WOULD SWITCH BACK TO THE data DATAFRAME AND DO IT ALL OVER AGAIN.\n",
    "\n",
    "def initial(df):\n",
    "    df = df.drop(columns=['Scn', 'Class']) # DROP THESE ONCE AT THE BEGINNING AND CALL THE DATASET 'TRAIN'\n",
    "    # ref - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n",
    "    return df.sample(2)\n",
    "\n",
    "\n",
    "def get_cluster_value(df, index, mu_2, mu_4):\n",
    "    df = df.drop(columns=['Scn', 'Class'])\n",
    "    \n",
    "    # GOOD, WE'LL RETURN TO THE INDEX IN A SECOND, BUT START BELOW.\n",
    "    \n",
    "    dist_from_centroid_2 = np.sqrt(np.square(df.loc[index] - mu_2).sum())\n",
    "    dist_from_centroid_4 = np.sqrt(np.square(df.loc[index] - mu_4).sum())\n",
    "    \n",
    "    # YOU DON'T HAVE TO DO BELOW.  YOU GOTTA START THINKING IN TERMS OF SERIES AND FRAMES WHICH ACT LIKE VECTORS \n",
    "    # A) WHAT YOU HAVE ABOVE IS ALREDY COMPUTING A SERIES (VECTOR) BUT HERE YOU ARE ONLY RETURNING ONE VALUE.  WHEN \n",
    "    # YOU WRITE YOUR IF, WHAT YOUR ASKING IS IF THE *ENTIRE* SERIES (VECTOR) dist_from_centroid_2 IS LESS THAN THE \n",
    "    # *ENTIRE* SERIES (VECTOR) dist_from_centroid_4.  IF IT IS, YOUR RETURNING THE SINGLE DIGIT (SCALER) 2 OR 4 \n",
    "    # DEPENDING.  THIS IS WHAT'S CAUSING YOU TO HAVE TO LOOP IN YOUR ASSIGN CLUSTER FUNCTION\n",
    "    \n",
    "# %%%%% REMOVE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   \n",
    "#     if(dist_from_centroid_2 < dist_from_centroid_4):\n",
    "#         return 2\n",
    "#     if(dist_from_centroid_4 < dist_from_centroid_2):\n",
    "#         return 4\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "    # INSTEAD, YOU CAN DO ONE OF A BUNCH OF THIGNS:\n",
    "    \n",
    "    # OPTION 1: 4 LINES\n",
    "    df['predicted'] = dist_2 < dist_4\n",
    "    df['predicted'].head()\n",
    "    # TRUE\n",
    "    # FALSE\n",
    "    # TRUE\n",
    "    # FALSE\n",
    "    # TRUE\n",
    "    \n",
    "    df.loc[df['predicted'] == True, 'predicted'] = 2\n",
    "    df.loc[df['predicted'] == False, 'predicted'] = 4\n",
    "    df.head()\n",
    "    # 2\n",
    "    # 4\n",
    "    # 2\n",
    "    # 4\n",
    "    # 2\n",
    "    \n",
    "    # OPTION 2: EVEN BETTER, THREE LINES!\n",
    "    \n",
    "    df['predicted'] = dist_2 < dist_4\n",
    "    df['predicted'] = df['predicted'].replace({True: 2, False: 4})\n",
    "    \n",
    "    # OPTION 3: EVEN MORE BETTER, ONE LINE!\n",
    "    \n",
    "    df['predicted'] = (dist_2 < dist_4).replace({True: class_a, False: class_b})\n",
    "    \n",
    "    # THIS IS ALL PERMITTED BECAUSE I'M USING SERIES dist_2 < dist_4 RETURNS A SERIES OF TRUE'S AND FALSE'S THEN\n",
    "    # I'M SAYING TO PUT A 2 IN THE SERIES WHEREVER A TRUE IS AND A 4 IN THE SERIES WHEREVER A FALSE IS.  THEN I'M\n",
    "    # STICKING THE ENTIRE SERIES INTO THE DATAFRAME AS A COLUMN (WHICH IS A SERIES).\n",
    "    \n",
    "    # SO IF YOU DON'T NEED A LOOP ANYMORE, THAT MEANS YOU DON'T NEED AN INDEX!  THEREFORE YOUR WHOLE FUNCTION \n",
    "    # BECOMES: \n",
    "    \n",
    "    def get_cluster_value(df, mu_2, mu_4):\n",
    "        df = df.drop(columns=['Scn', 'Class'])\n",
    "\n",
    "        # NO INDEX BECAUSE IT WILL DO WHAT YOU HAVE BELOW TO THE *ENTIRE* DATAFRAME AUTOMATICALLY!\n",
    "\n",
    "        dist_from_centroid_2 = np.sqrt(np.square(df - mu_2).sum())\n",
    "        dist_from_centroid_4 = np.sqrt(np.square(df - mu_4).sum())\n",
    "        \n",
    "        # IT'S YOUR CHOICE FROM ABOVE BUT WE CAN GO MIDWAY SO THAT PEOPLE CAN SEE THE STEPS\n",
    "        \n",
    "        # IS RETURNS A *SERIES* THAT ARE BOOLEANS WHERE THE CONDITION IS TRUE VS. FALSE\n",
    "        cluster_assign =  dist_from_centroid_2 < dist_from_centroid_4\n",
    "\n",
    "        # REPLACES THE TRUE'S AND FALSE'S WITH 2's and 4's\n",
    "        cluster_assign = cluster_assign.replace({True: 2, False: 4})\n",
    "        \n",
    "        # ADDS THE SERIES TO THE DATAFRAME AS A NEW COLUMN\n",
    "        df[\"Predicted_Class\"] = cluster_assign\n",
    "\n",
    "    \n",
    "    # BY THE WAY.  IN YOUR CURRENT ASSIGN CLUSTER FUNCTION, I THINK YOU ARE TRYING TO APPEND A SINGLE CELL IN EACH\n",
    "    # COLUMN TOGETHER TO MAKE A ROW?  NO NEED.  YOU SHOULDN'T BE LOOPING ANYWAY, BUT IF YOU WERE, YOU CAN ASK FOR\n",
    "    # df.iloc[n] WHERE n IS A NUMBER IN THE INDEX. YOU CAN REMEMBER THAT iloc GETS YOU ROW'S BECUASE THE i IS FOR\n",
    "    # INDEX.  YOU'RE SAYING, GET ME THE ROW AT INDEX n.  ASIDE: YOU CAN ALSO GET THE NUMBER OF AN INDEX BY DOING\n",
    "    # df.index[n].  BOTH WORK WITH THINGS LIKE THIS df.iloc[4:10] AS WELL\n",
    "    \n",
    "    # SO THINK ABOUT THIS AND TRY TO START THINKING IN THIS WAY.  SEE HOW IT WOULD CHANGE YOUR APPROACH WERE YOU TO\n",
    "    # HAVE THE TIME TO DO IT.\n",
    "    \n",
    "    # SMALL NOTE: DON'T FfORGET TO ADD A CELL FOR MAIN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3c4fdb01648d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#invoke main method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-3c4fdb01648d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A7'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdf_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial' is not defined"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def recompute(cluster_2,cluster_4):\n",
    "    cluster_2 = cluster_2.drop(columns=['Scn', 'Class','predicted_class'])\n",
    "    cluster_4 = cluster_4.drop(columns=['Scn', 'Class','predicted_class'])\n",
    "    return cluster_2.mean(axis = 0), cluster_4.mean(axis = 0) # .mean() is already zero by default\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign_cluster(df,mu_2,mu_4):\n",
    "    col1 = [\"Scn\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"Class\",\"predicted_class\"]\n",
    "    predicted_clusters = pd.DataFrame()\n",
    "    for i in range(len(df)):\n",
    "#         data = pd.Series([df[\"Scn\"].loc[i],\n",
    "#                           df[\"A2\"].loc[i],\n",
    "#                           df[\"A3\"].loc[i],\n",
    "#                           df[\"A4\"].loc[i],\n",
    "#                           df[\"A5\"].loc[i],\n",
    "#                           df[\"A6\"].loc[i],\n",
    "#                           df[\"A7\"].loc[i],\n",
    "#                           df[\"A8\"].loc[i],\n",
    "#                           df[\"A9\"].loc[i],\n",
    "#                           df[\"A10\"].loc[i],\n",
    "#                           df[\"Class\"].loc[i]\n",
    "#                           ,get_cluster_value(df,i,mu_2,mu_4)], index = col1)\n",
    "#         print(data)\n",
    "        \n",
    "        predicted_clusters = predicted_clusters.append(pd.Series([df[\"Scn\"].loc[i],\n",
    "                                                                  df[\"A2\"].loc[i],\n",
    "                                                                  df[\"A3\"].loc[i],\n",
    "                                                                  df[\"A4\"].loc[i],\n",
    "                                                                  df[\"A5\"].loc[i],\n",
    "                                                                  df[\"A6\"].loc[i],\n",
    "                                                                  df[\"A7\"].loc[i],\n",
    "                                                                  df[\"A8\"].loc[i],\n",
    "                                                                  df[\"A9\"].loc[i],\n",
    "                                                                  df[\"A10\"].loc[i],\n",
    "                                                                  df[\"Class\"].loc[i]\n",
    "                                                                  ,get_cluster_value(df,i,mu_2,mu_4)], index = col1) ,ignore_index=True)\n",
    "        \n",
    "    return predicted_clusters\n",
    "\n",
    "\n",
    "    \n",
    "def loop_through(df,mu_2,mu_4):\n",
    "    for i in range(1,51):\n",
    "#         print(\"mu_2 :\", mu_2)\n",
    "#         print(\"mu_4 :\", mu_4)\n",
    "        predicted_clusters = assign_cluster(df,mu_2,mu_4)\n",
    "            \n",
    "        cluster_2 = predicted_clusters.loc[predicted_clusters['predicted_class'] == 2]\n",
    "        cluster_4 = predicted_clusters.loc[predicted_clusters['predicted_class'] == 4]\n",
    "    \n",
    "        new_mu_2, new_mu_4 = recompute(cluster_2,cluster_4)\n",
    "        if(np.array_equal(new_mu_2, mu_2) & np.array_equal(new_mu_4, mu_4)):\n",
    "#             print(\"centroids matched with previous centroids. No change in centroids\")\n",
    "            return i, mu_2, mu_4, predicted_clusters\n",
    "            break;\n",
    "        else:\n",
    "            mu_2 = new_mu_2\n",
    "            mu_4 = new_mu_4\n",
    "    return i, mu_2, mu_4, predicted_clusters \n",
    "            \n",
    "\n",
    "\n",
    "def main():\n",
    "    #ref - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html\n",
    "    pd.set_option('precision', 0)\n",
    "    \n",
    "    col = [\"Scn\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"Class\"]\n",
    "    \n",
    "    # read from file\n",
    "    df = pd.read_csv('breast-cancer-wisconsin.data', na_values = '?', names = col)\n",
    " \n",
    "    # replace missing value with mean\n",
    "    df = df.fillna(df.mean()['A7'])\n",
    "    \n",
    "    df_sample = initial(df)\n",
    "    \n",
    "    count = 2\n",
    "    for index, row in df_sample.iterrows():\n",
    "        print(\"Randomly selected row \",index, \"for centroid mu_\"+str(count), end=\"\\n\\n\")\n",
    "        print(\"Initial centroid mu_\"+str(count)+\":\")\n",
    "        print(row,end=\"\\n\\n\")\n",
    "        count += 2\n",
    "    \n",
    "    mu_2 , mu_4 = df_sample.values[0].astype(int), df_sample.values[1].astype(int)\n",
    "    \n",
    "    i,final_mu_2,final_mu_4, predicted_clusters = loop_through(df,mu_2,mu_4)\n",
    "\n",
    "    print(\"Program ended after \",i, \" iterations.\",end=\"\\n\\n\")\n",
    "    print(\"Final centroid mu_2:\\n\",final_mu_2,end=\"\\n\\n\")\n",
    "    print(\"Final centroid mu_4:\\n\",final_mu_4,end=\"\\n\\n\")\n",
    "    print(\"Final cluster assignment:\",end=\"\\n\\n\")\n",
    "    predicted_clusters = predicted_clusters[['Scn', 'Class', 'predicted_class']]\n",
    "    print(predicted_clusters,end=\"\\n\\n\")\n",
    "#     print(predicted_clusters.head(20),end=\"\\n\\n\")\n",
    "    \n",
    "    cluster_2 = predicted_clusters.loc[predicted_clusters['predicted_class'] == 2]\n",
    "    cluster_4 = predicted_clusters.loc[predicted_clusters['predicted_class'] == 4]\n",
    "    print(\"Data points in Predicted Class 2: \",cluster_2.shape[0])\n",
    "    print(\"Data points in Predicted Class 4: \",cluster_4.shape[0],end=\"\\n\\n\")\n",
    "    \n",
    "    error_cluster_2 = cluster_2.loc[cluster_2['Class']== 4]\n",
    "    error_cluster_4 = cluster_4.loc[cluster_4['Class']== 2]\n",
    "    print(\"Error data points, Predicted Class 2:\\n\",error_cluster_2,end=\"\\n\\n\")\n",
    "    print(\"Error data points, Predicted Class 4:\\n\",error_cluster_4,end=\"\\n\\n\")\n",
    "     \n",
    "    print(\"Number of all data points:   \", predicted_clusters.shape[0],end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Number of error data points: \", error_cluster_2.shape[0] + error_cluster_4.shape[0],end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Error rate for class 2:      \", round((error_cluster_2.shape[0]/predicted_clusters.shape[0])*100,1),\"%\")\n",
    "    print(\"Error rate for class 4:      \", round((error_cluster_4.shape[0]/predicted_clusters.shape[0])*100,1),\"%\")\n",
    "    print(\"Total error rate:            \", round(((error_cluster_2.shape[0] + error_cluster_4.shape[0])/predicted_clusters.shape[0])*100,1),\"%\")\n",
    "    \n",
    "    \n",
    "#invoke main method\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
